{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwsTxgm2qULEAChYwWkfsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lennyciotti/Feedback_squared/blob/main/feedback_desk_gpt_judge_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0ZneezuuYpnM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from typing import Dict, Any\n",
        "from google.colab import userdata\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://us.api.openai.com/v1/\")\n",
        "print(\"API loaded:\", bool(api_key))\n",
        "\n",
        "if api_key:\n",
        "    print(\"‚úÖ OpenAI API key is loaded!\")\n",
        "else:\n",
        "    print(\"‚ùå OpenAI API key NOT loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KoqFoxNY8Gh",
        "outputId": "0dd69ee2-f705-497c-d532-a8659f6c8f2b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API loaded: True\n",
            "‚úÖ OpenAI API key is loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_ROLE_JUDGE = \"\"\"\n",
        "You are a judge that evaluates feedback on written assignments.\n",
        "You are judging the feedback's {tone}, its level of {detail}, and how appropriate the feedback is around {grammar}, {structure} as well as {content}.\n",
        "You will receive both the original essay and the feedback.\n",
        "The feedback is broken into two sections, high level feedback on the entire assignment and comments\n",
        "which contains tone, level of detail, grammar, structure and content.\n",
        "For each assignment you will one score for each dimension of feedback.\n",
        "Your evaluation must strictly adhere to the provided dimensions.\n",
        "Your response must be and can only be a JSON object, containing no introductory text outside the JSON format (such as ‚ÄúHere is the evaluation...‚Äù).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rR4hza_zZCWY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EVALUATION_RUBRIC = \"\"\"\n",
        "Please rate and evaluate this feedback according to the following criteria.\n",
        "[Evaluation Criteria]\n",
        "1.  Tone[1-5 points]: For tone you will consider the high level feedback and the comments and judge if the feedback's tone is\n",
        "    4 = Very positive and encouraging\n",
        "    3 = Somewhat positive and encouraging\n",
        "    2 = Not really positive and encouraging\n",
        "    1 = Not at all positive and encouraging\n",
        "2.  Level of detail [1-5 points]: For the level of detail you will consider the high level feedback and the comments and judge if the feedback:\n",
        "    4 = Very detailed, specific and actionable\n",
        "    3 = Somewhat detailed, specific and actionable\n",
        "    2 = Not really detailed, specific and actionable\n",
        "    1 = Not at all detailed specific or actionable\n",
        "3.  Grammar [1-5 points]: For grammar you will consider both the original essay and the high level feedback and comments and judge if the grammar feedback:\n",
        "    4 = Addressed all grammar and mechanics issues in the original essay\n",
        "    3 = Addressed most grammar and mechanics issues in the original essay\n",
        "    2 = Addressed some grammar and mechanics issues in the original essay\n",
        "    1 = Addressed none of the grammar and mechanics issues in the original essay\n",
        "4.  Stucture [1-5 points]: For stucture you will consider both the original essay and the high level feedback and comments and judge if the stucture feedback:\n",
        "    4 = Addressed all stucture and mechanics issues in the original essay\n",
        "    3 = Addressed most stucture and mechanics issues in the original essay\n",
        "    2 = Addressed some stucture and mechanics issues in the original essay\n",
        "    1 = Addressed none of the stucture and mechanics issues in the original essay\n",
        "5.  Content [1-5 points]: For content you will consider both the original essay and the high level feedback and comments and judge if the content feedback:\n",
        "    4 = Addressed all content and mechanics issues in the original essay\n",
        "    3 = Addressed most content and mechanics issues in the original essay\n",
        "    2 = Addressed some content and mechanics issues in the original essay\n",
        "    1 = Addressed none of the content and mechanics issues in the original essay\n",
        "\n",
        "[Output Format]\n",
        "Please strictly adhere to the following JSON format when returning your evaluation results:\n",
        "{\n",
        "  \"Tone\": <score (int)>,\n",
        "  \"Level of detail\": <score (int)>,\n",
        "  \"Grammar\": <score (int)>,\n",
        "  \"Stucture\": <score (int)>,\n",
        "  \"Content\": \"<score (int)>\"\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vPJutb_2ZGXM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Input student sample data and the Feedback Desk feedback data from google drive saved pkl file.\"\"\""
      ],
      "metadata": {
        "id": "s1jLGSxaZUee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEx5pnjWZbCo",
        "outputId": "d75023d0-496b-4576-d085-76553977e2eb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONNECT TO THE SAMPLES DATABASE\n",
        "\n",
        "# Define the path to your pickle file\n",
        "pickle_file_path = '/content/drive/MyDrive/Fall 2025/Practicum in Data Analysis/Copy of SAMPLES.pkl'\n",
        "\n",
        "# Unpickle the file into a DataFrame\n",
        "samples_df = pd.read_pickle(pickle_file_path)\n",
        "\n",
        "# Now 'df' is your unpickled pandas DataFrame\n",
        "print(samples_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSDWkqcRZl1e",
        "outputId": "97ed3e33-31b0-4b1c-8ff6-6a2080abb0fc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   essay_id      created_at  \\\n",
            "0  2d75e7f0  11/18/25 18:22   \n",
            "1  1f20d82f  11/18/25 18:22   \n",
            "2  00b8f343  11/18/25 18:22   \n",
            "3  b1b156cc  11/18/25 18:22   \n",
            "4  332031c4  11/18/25 18:22   \n",
            "\n",
            "                                               title  subject      grade  \\\n",
            "0  Thomas Jefferson And The Declaration Of Indepe...  History  9th grade   \n",
            "1  Thomas Jefferson And The Declaration Of Indepe...  History  9th grade   \n",
            "2  Thomas Jefferson And The Declaration Of Indepe...  History  9th grade   \n",
            "3  Thomas Jefferson And The Declaration Of Indepe...  History  9th grade   \n",
            "4  Thomas Jefferson And The Declaration Of Indepe...  History  9th grade   \n",
            "\n",
            "             knowledge level                                   grammar level  \\\n",
            "0       3 - medium knowledge                  4 - good grammar and structure   \n",
            "1         4 - deep knowledge  5 - great form, grammar and a broad vocabulary   \n",
            "2  2 - superficial knowledge     3 - decent grammar but very basic structure   \n",
            "3       3 - medium knowledge     3 - decent grammar but very basic structure   \n",
            "4         4 - deep knowledge                  4 - good grammar and structure   \n",
            "\n",
            "                                          flow level  \\\n",
            "0  3 - adequate flow and organization, the thesis...   \n",
            "1  4 - good flow and well-organized. The thesis i...   \n",
            "2  1 - poor flow and organization. There is no th...   \n",
            "3  4 - good flow and well-organized. The thesis i...   \n",
            "4  5 - excellent flow and highly organized. The t...   \n",
            "\n",
            "                                               essay  \n",
            "0  ## Thomas Jefferson and the Declaration of Ind...  \n",
            "1  ### Thomas Jefferson and the Declaration of In...  \n",
            "2  **Thomas Jefferson and the Declaration of Inde...  \n",
            "3  ### Thomas Jefferson and the Declaration of In...  \n",
            "4  **Thomas Jefferson and the Declaration of Inde...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONNECT TO THE FEEDBACK RESULTS DATABASE\n",
        "\n",
        "# Define the path to your pickle file\n",
        "pickle_file_path = '/content/drive/MyDrive/Fall 2025/Practicum in Data Analysis/feedback_results_df.pkl'\n",
        "\n",
        "# Unpickle the file into a DataFrame\n",
        "results_df = pd.read_pickle(pickle_file_path)\n",
        "\n",
        "# Now 'df' is your unpickled pandas DataFrame\n",
        "print(results_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdEyRBafZsbR",
        "outputId": "8d2060d0-f30b-4fb5-faf0-192b3c09d918"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   essay_id                                high_level_feedback  \\\n",
            "0  2d75e7f0  <p>This essay provides a comprehensive overvie...   \n",
            "1  1f20d82f  <p>This essay provides a comprehensive overvie...   \n",
            "2  00b8f343  <p>This assignment provides a clear and concis...   \n",
            "3  b1b156cc  <p>This essay provides a comprehensive overvie...   \n",
            "4  332031c4  <p>This assignment provides a comprehensive ov...   \n",
            "\n",
            "                                            comments  \n",
            "0  [{'label': 'Glow: Significance of Jefferson's ...  \n",
            "1  [{'label': 'Glow: Clear and Structured Introdu...  \n",
            "2  [{'label': 'Glow: Jefferson's Role', 'comment_...  \n",
            "3  [{'label': 'Glow: Clear Outline of Jefferson's...  \n",
            "4  [{'label': 'Historical Context', 'comment_text...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "from typing import Dict, Any\n",
        "from google.colab import userdata\n",
        "from tqdm import tqdm\n",
        "\n",
        "\"\"\"***2. Core Evaluation Logic***\\n\\nThis function acts as the bridge between our data and the LLM API.\\n\\nInput: It takes the Student Essay and the Feedback Desk Output.\\n\\nPrompt Engineering: It constructs a structured prompt combining the essay, feedback, and the grading rubric.\\n\\nAPI Call: It sends the request to the model (forcing a JSON output for structured data) and handles any potential connection errors.\\n\"\"\"\n",
        "\n",
        "def get_llm_evaluation(essay: str, feedback: str, client: OpenAI) -> Dict[str, Any] | None:\n",
        "    \"\"\"\n",
        "    Construct the prompt and invoke the GPT-4o-mini model to obtain the evaluation.\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "    [Original student essay]\n",
        "    {essay}\n",
        "\n",
        "    [Feedback Desk's feedback]\n",
        "    {feedback}\n",
        "\n",
        "    [Evaluation Criteria and Output Format]\n",
        "    {EVALUATION_RUBRIC}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_ROLE_JUDGE},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            response_format={\"type\": \"json_object\"},\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        # The new API returns text via .output_text\n",
        "        output_text = response.choices[0].message.content\n",
        "\n",
        "        # Parse JSON\n",
        "        evaluation_data = json.loads(output_text)\n",
        "        return evaluation_data\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"‚ùå Error: Model did not return valid JSON.\")\n",
        "        print(f\"Raw model output:\\n{output_text}\")\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error calling OpenAI API: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "hNAKObQwZxjE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"***3. Data Processing & Batch Execution***\n",
        "\n",
        "This is the main execution loop of the pipeline.\n",
        "\n",
        "Data Loading: Reads the .pkl files using Pandas.\n",
        "\n",
        "Data Merging: Joins the Samples and Results dataframes on essay_id to ensure we are evaluating the correct pairs.\n",
        "\n",
        "Batch Processing: Iterates through every row (with a progress bar), cleans column names, sends data to the LLM, and collects the results.\n",
        "\n",
        "Saving: Finally, exports the evaluation results to a new .pkl file in Google Drive.\n",
        "\"\"\"\n",
        "\n",
        "def main():\n",
        "    # Define Path\n",
        "    INPUT_PKL_PATH_SAMPLES = '/content/drive/MyDrive/Fall 2025/Practicum in Data Analysis/Copy of SAMPLES.pkl'\n",
        "    INPUT_PKL_PATH_RESULTS = '/content/drive/MyDrive/Fall 2025/Practicum in Data Analysis/feedback_results_df.pkl'\n",
        "    OUTPUT_PKL_PATH = '/content/drive/MyDrive/Fall 2025/Practicum in Data Analysis/GPT_judges_evaluation_results.pkl'\n",
        "\n",
        "    results_list = []\n",
        "\n",
        "    # 1. load data\n",
        "    try:\n",
        "        print(\"Loading data...\")\n",
        "        samples_df = pd.read_pickle(INPUT_PKL_PATH_SAMPLES)\n",
        "        results_df = pd.read_pickle(INPUT_PKL_PATH_RESULTS)\n",
        "\n",
        "        samples_df['essay_id'] = samples_df['essay_id'].astype(str)\n",
        "        results_df['essay_id'] = results_df['essay_id'].astype(str)\n",
        "\n",
        "        # Merge Data\n",
        "        # Use inner join to ensure only records with both original text and feedback are processed\n",
        "        merged_data = pd.merge(samples_df, results_df, on='essay_id', how='inner')\n",
        "\n",
        "        # Remove duplicates! Prevent duplicate rows from appearing in the original data.\n",
        "        merged_data = merged_data.drop_duplicates(subset=['essay_id'])\n",
        "\n",
        "        print(f\"‚úÖ Data merged! Total unique essays to process: {len(merged_data)}\")\n",
        "\n",
        "        print(f\"üîç Debug: Merged Columns: {merged_data.columns.tolist()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading data: {e}\")\n",
        "        return\n",
        "\n",
        "# 2. Loop processing (using tqdm to display progress bar)\n",
        "    print(\"üöÄ Starting Batch Evaluation...\")\n",
        "\n",
        "    for index, row in tqdm(merged_data.iterrows(), total=len(merged_data)):\n",
        "        # Retrieve the ID (preferably essay_id)\n",
        "        current_id = row.get('essay_id', row.get('sample_id', f'Unknown_{index}'))\n",
        "\n",
        "        # Retrieve article content\n",
        "        if 'essay' in row:\n",
        "            current_essay = row['essay']\n",
        "        elif 'essay_text' in row:\n",
        "            current_essay = row['essay_text']\n",
        "        # Handling potential suffix combinations\n",
        "        elif 'essay_x' in row:\n",
        "            current_essay = row['essay_x']\n",
        "        elif 'essay_y' in row:\n",
        "            current_essay = row['essay_y']\n",
        "        else:\n",
        "            # Only when none of the above names can be found should an error be reported.\n",
        "            print(f\"‚ö†Ô∏è Column missing for ID {current_id}: Check column names!\")\n",
        "            current_essay = \"\"\n",
        "\n",
        "        # Get feedback (also check if high_level_feedback has a suffix)\n",
        "        high_level = row.get('high_level_feedback', row.get('high_level_feedback_x', row.get('high_level_feedback_y', '')))\n",
        "        comments = row.get('comments', row.get('comments_x', row.get('comments_y', '')))\n",
        "        current_feedback = f\"High Level Feedback:\\n{high_level}\\n\\nSpecific Comments:\\n{comments}\"\n",
        "\n",
        "        # Inspection Content\n",
        "        if pd.isna(current_essay) or len(str(current_essay)) < 10:\n",
        "            # Only when it's truly empty will it skip.\n",
        "            print(f\"‚ö†Ô∏è Skip ID {current_id}: Content empty.\")\n",
        "            continue\n",
        "\n",
        "        # Call GPT (passing the current line's essay and feedback)\n",
        "        evaluation = get_llm_evaluation(current_essay, current_feedback, client)\n",
        "\n",
        "        if evaluation:\n",
        "            evaluation['essay_id'] = current_id # Record the correct ID\n",
        "            results_list.append(evaluation)\n",
        "        else:\n",
        "            # Failed to record\n",
        "            results_list.append({\n",
        "                \"essay_id\": current_id\n",
        "            })\n",
        "\n",
        "# 3. Save results\n",
        "    final_df = pd.DataFrame(results_list)\n",
        "\n",
        "    # Perform another deduplication to ensure absolute reliability.\n",
        "    final_df = final_df.drop_duplicates(subset=['essay_id'])\n",
        "\n",
        "    print(f\"\\nüíæ Saving {len(final_df)} unique results to Drive...\")\n",
        "    final_df.to_pickle(OUTPUT_PKL_PATH)\n",
        "\n",
        "    print(\"üéâ Done! Preview:\")\n",
        "    print(final_df.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLR2QVxyaC8X",
        "outputId": "6a134281-0fff-4f2c-a0b7-34a043c4dd92"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "‚úÖ Data merged! Total unique essays to process: 122\n",
            "üîç Debug: Merged Columns: ['essay_id', 'created_at', 'title', 'subject', 'grade', 'knowledge level', 'grammar level', 'flow level', 'essay', 'high_level_feedback', 'comments']\n",
            "üöÄ Starting Batch Evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122/122 [02:53<00:00,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Saving 122 unique results to Drive...\n",
            "üéâ Done! Preview:\n",
            "   Tone  Level of detail  Grammar  Stucture  Content  essay_id\n",
            "0     4                4        1         1        3  2d75e7f0\n",
            "1     4                4        1         4        3  1f20d82f\n",
            "2     4                4        1         1        3  00b8f343\n",
            "3     4                4        1         1        3  b1b156cc\n",
            "4     4                4        1         4        3  332031c4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}